{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421e47f5-552d-48a7-af21-d39d8ee5248b",
   "metadata": {},
   "source": [
    "# Change detection of chaotic time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44197f-d3e7-4e9d-94fa-0d2a468df44f",
   "metadata": {},
   "source": [
    "In this note book, we apply our methods to a chaotic time-series generated by the Lorenz equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb3e38-d118-4b6e-b0b4-f8f695392f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as gd\n",
    "from gudhi.representations import Landscape\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9d2a9-e2e2-4048-900f-9123e760a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdl.model import Norm1D\n",
    "from mdl.smdl import SMDL\n",
    "from bocpd.mybocpd import BOCD, StudentT, constant_hazard\n",
    "from mdl.ppm import get_K_mu_sigma\n",
    "from mdl.wkc import get_WKC\n",
    "from utils.evaluation import calc_auc_average, calc_falarms_benefit, InvRunLen\n",
    "from utils.embedding import TimeDelayEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f7cfc-943d-4339-8dee-eddcab2fd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb450d9f-37b0-4bc1-a3c2-4ba5b9fb6dd0",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "We generate a time-series using the Lorenz equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84128c-3af0-4c24-9483-3d98d5df0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz(x, y, z, p,r,b):\n",
    "    x_dt = p*(y-x)\n",
    "    y_dt = x*(r-z)-y\n",
    "    z_dt = x*y-b*z\n",
    "    return x_dt, y_dt, z_dt\n",
    "\n",
    "def get_chaos_data(r,t):\n",
    "    dt = 0.02\n",
    "    num_steps = 1500\n",
    "    p = 10\n",
    "    b = 8/3\n",
    "    x = [0.01]\n",
    "    y = [0.01]\n",
    "    z = [0.01]\n",
    "    for i in range(num_steps):\n",
    "        if i==(num_steps-2*t):\n",
    "            r = 35\n",
    "        if i==(num_steps-t):\n",
    "            r = 40\n",
    "\n",
    "        x_dt, y_dt, z_dt = lorenz(x[-1], y[-1], z[-1],p,r,b)\n",
    "        x.append(x[-1] + (x_dt * dt))\n",
    "        y.append(y[-1] + (y_dt * dt))\n",
    "        z.append(z[-1] + (z_dt * dt))\n",
    "\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec2b8e-45ce-4677-8218-1eb40b4cd92b",
   "metadata": {},
   "source": [
    "## Time-delay embedding\n",
    "Apply time-delay embedding to the time-series data and convert it to a series of three-dimensional point clouds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881edbb-26c2-467a-a609-324b75856293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_chaos_data(28,500)[0]\n",
    "TimeDelayWindow = TimeDelayEmbedding(250,1,1)\n",
    "ex_data = TimeDelayWindow(data,0)\n",
    "TimeDelay = TimeDelayEmbedding(3,5,1)\n",
    "use_data = TimeDelay(ex_data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50410c6-a4c0-47bd-a31e-3d17a366501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d6b64-1a15-4793-afcf-5bd9d30bd471",
   "metadata": {},
   "source": [
    "## Number of optimal components in Persistence Parametric Model\n",
    "We apply the PPM method to the PDs of the point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a49b46-ec32-4409-888e-bcb3fe72e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = []\n",
    "max_K = 7\n",
    "b = 1\n",
    "for i in range(len(use_data)):\n",
    "    ob_data = use_data[i]\n",
    "    rips_complex = gd.RipsComplex(points=ob_data)\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    diag = simplex_tree.persistence()\n",
    "    A = simplex_tree.persistence_intervals_in_dimension(1)\n",
    "    K, mu, sigma = get_K_mu_sigma(A, max_K, b)\n",
    "    Ks.append(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e133e36-205f-4b6f-9991-bbe53d8ea776",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5eba44-4778-4338-a9e6-9463549326fb",
   "metadata": {},
   "source": [
    "We plot the centers of PPM at several time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40cb05-9db3-47d7-a0ad-f2c2b9767aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [100,600,1100]:\n",
    "    ob_data = use_data[i]\n",
    "    rips_complex = gd.RipsComplex(points=ob_data)\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    diag = simplex_tree.persistence()\n",
    "    A = simplex_tree.persistence_intervals_in_dimension(1)\n",
    "    K, mu, sigma = get_K_mu_sigma(A, max_K, b)\n",
    "    \n",
    "    plt.scatter(A.T[0],A.T[1]-A.T[0])\n",
    "    for l in range(K):\n",
    "        plt.scatter(mu[l][0],mu[l][1],color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047229e-7110-4357-89c0-adc636df5833",
   "metadata": {},
   "source": [
    "We smooth the series of the number of mixture components and apply Bayesian online change point detection (BOCPD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2c680-159e-4eab-9ecd-658ab7db2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 3\n",
    "smooth_Ks = [0]*(smooth-1)\n",
    "for i in range(smooth-1,len(Ks)):\n",
    "    smooth_Ks.append(np.mean(Ks[i-smooth+1:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3aef7-4776-4559-af88-235ad905de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.1\n",
    "BETA = 1.0\n",
    "KAPPA = 1.0\n",
    "MU = 0.0\n",
    "DELAY = 15\n",
    "N_trial = 1\n",
    "T = 200\n",
    "\n",
    "for LAMBDA in [50,100,150,200,250,300]:\n",
    "    for THRESHOLD in [0.1, 0.3]:\n",
    "        scores_bocpd = []\n",
    "        for i in range(N_trial):\n",
    "            X = smooth_Ks\n",
    "\n",
    "            # BOCPD\n",
    "            bocd = BOCD(partial(constant_hazard, LAMBDA),\n",
    "                        StudentT(ALPHA, BETA, KAPPA, MU), X)\n",
    "            change_points = []\n",
    "            scores = [np.nan] * DELAY\n",
    "            for x in X[:DELAY]:\n",
    "                bocd.update(x)\n",
    "            for x in X[DELAY:]:\n",
    "                bocd.update(x)\n",
    "                if bocd.growth_probs[DELAY] >= THRESHOLD:\n",
    "                    change_points.append(bocd.t - DELAY + 1)\n",
    "                score = np.sum(bocd.growth_probs[:bocd.t - DELAY] * 1.0 / (1.0 + np.arange(1, bocd.t - DELAY + 1)))\n",
    "                scores.append(score)\n",
    "\n",
    "            scores_bocpd.append(scores)\n",
    "\n",
    "        scores_bocpd = np.array(scores_bocpd)\n",
    "        auc_list = calc_auc_average(scores_bocpd,np.array([250,750]), T=T)\n",
    "        print('LAMBDA =', LAMBDA, 'THRESHOLD =', THRESHOLD, 'AUC:', np.mean(auc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad35e21-e00c-49f7-8cd7-3978fedac8f2",
   "metadata": {},
   "source": [
    "## Kernel Complexity of Persistence Non-Parametric Model\n",
    "We apply the PNPM method to the PDs of the point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefceeaa-80ba-4faa-ae53-fe96e98aa3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "KCs_PNPM = []\n",
    "epsilon = 0.1\n",
    "gamma = 0.7\n",
    "param = 1.0\n",
    "for i in range(len(use_data)):\n",
    "    ob_data = use_data[i]\n",
    "    rips_complex = gd.RipsComplex(points=ob_data)\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension = 2)\n",
    "    diag = simplex_tree.persistence()\n",
    "    A = simplex_tree.persistence_intervals_in_dimension(1)\n",
    "    x1 = np.append(np.array([A.T[0]]),[A.T[1]-A.T[0]],axis=0)\n",
    "    x = x1.T\n",
    "    n = len(x)\n",
    "    m = len(x[0])\n",
    "    if len(x) > 0:\n",
    "        KC = get_WKC(x, n, m, gamma, epsilon, param)\n",
    "        KCs_PNPM.append(KC)\n",
    "    else:\n",
    "        KCs_PNPM.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc6cce-c212-43e9-b813-2c17d0cb4c51",
   "metadata": {},
   "source": [
    "We apply sequential MDL-change statistics (SMDL) to the series of the kernel complexity of PNPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c3543-9d87-455f-8cc5-50b7ddf1fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 70\n",
    "cps_true = np.array([250,750])\n",
    "N_trial = 1\n",
    "mu_max = 50.0\n",
    "sigma_min = 0.005\n",
    "T = 200\n",
    "\n",
    "scores_list_0th = []\n",
    "scores_list_1st = []\n",
    "scores_list_2nd = []\n",
    "for i in range(N_trial):\n",
    "    X = np.array(KCs_PNPM)\n",
    "    len_X = len(X)\n",
    "    \n",
    "    norm1d = my_Norm1D()\n",
    "    smdl = SMDL(norm1d)\n",
    "\n",
    "    scores_0th = np.array([np.nan]*h + [ smdl.calc_change_score(X[(t-h):(t+h)], h, mu_max=mu_max, sigma_min=sigma_min) \\\n",
    "                                     for t in range(h, len_X-h)] + [np.nan]*h)\n",
    "    scores_list_0th.append(scores_0th)\n",
    "\n",
    "scores_list_0th = np.array(scores_list_0th)\n",
    "auc_list_0th = calc_auc_average(scores_list_0th, cps_true=cps_true,T=T)\n",
    "print(\"AUC:\", np.mean(auc_list_0th))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58788a8e-8f8f-474d-be2f-d5629de6fa7f",
   "metadata": {},
   "source": [
    "## Comparison with existing methods\n",
    "Below we apply several existing methods to the time-series for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1691f-8d95-41aa-83a2-077771577809",
   "metadata": {},
   "source": [
    "### L2 norm of persistence landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e2132-3fa4-4433-8ff1-6e337e84da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_norms = []\n",
    "for i in range(len(use_data)):\n",
    "    ob_data = use_data[i]\n",
    "    rips_complex = gd.RipsComplex(points=ob_data)\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    simplex_tree.persistence()\n",
    "    A = simplex_tree.persistence_intervals_in_dimension(1)\n",
    "    x1 = np.append(np.array([A.T[0]]),[A.T[1]-A.T[0]],axis=0)\n",
    "    x = x1.T\n",
    "    LS = Landscape(num_landscapes=3,resolution=1000)\n",
    "    L = LS.fit_transform([simplex_tree.persistence_intervals_in_dimension(1)])\n",
    "    L2 = 0\n",
    "    L2 += pow(np.linalg.norm(L[0][:1000],ord=2),2)\n",
    "    L2 += pow(np.linalg.norm(L[0][1000:2000],ord=2),2)\n",
    "    L2 += pow(np.linalg.norm(L[0][2000:3000],ord=2),2)\n",
    "    L2_norms.append(pow(L2,1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c622b9-2f37-4a3c-b562-2638817f3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 20\n",
    "cps_true = np.array([250,750])\n",
    "N_trial = 1\n",
    "mu_max = 50.0\n",
    "sigma_min = 0.005\n",
    "T = 200\n",
    "\n",
    "scores_list_0th = []\n",
    "scores_list_1st = []\n",
    "scores_list_2nd = []\n",
    "for i in range(N_trial):\n",
    "    X = np.array(L2_norms)\n",
    "    len_X = len(X)\n",
    "    \n",
    "    norm1d = Norm1D()\n",
    "    smdl = SMDL(norm1d)\n",
    "\n",
    "    scores_0th = np.array([np.nan]*h + [ smdl.calc_change_score(X[(t-h):(t+h)], h, mu_max=mu_max, sigma_min=sigma_min) \\\n",
    "                                     for t in range(h, len_X-h)] + [np.nan]*h)\n",
    "    scores_list_0th.append(scores_0th)\n",
    "    \n",
    "scores_list_0th = np.array(scores_list_0th)\n",
    "auc_list_0th = calc_auc_average(scores_list_0th, cps_true=cps_true,T=T)\n",
    "print(\"AUC:\", np.mean(auc_list_0th))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c652ea7-6a1f-4d94-b628-fad38aa4e1e2",
   "metadata": {},
   "source": [
    "### Sequential MDL-change statistics (SMDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acf8dd-8aec-480c-a11c-9bdb2cdee947",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 10\n",
    "cps_true=np.array([500,1000])\n",
    "N_trial = 1\n",
    "mu_max = 50.0\n",
    "sigma_min = 0.005\n",
    "T = 200\n",
    "\n",
    "scores_list_0th = []\n",
    "scores_list_1st = []\n",
    "scores_list_2nd = []\n",
    "for i in range(N_trial):\n",
    "    X = np.array(data)\n",
    "    len_X = len(X)\n",
    "    \n",
    "    norm1d = Norm1D()\n",
    "    smdl = SMDL(norm1d)\n",
    "\n",
    "    scores_0th = np.array([np.nan]*h + [ smdl.calc_change_score(X[(t-h):(t+h)], h, mu_max=mu_max, sigma_min=sigma_min) \\\n",
    "                                     for t in range(h, len_X-h)] + [np.nan]*h)\n",
    "    scores_list_0th.append(scores_0th)\n",
    "\n",
    "scores_list_0th = np.array(scores_list_0th)\n",
    "auc_list_0th = calc_auc_average(scores_list_0th, cps_true=cps_true,T=T)\n",
    "print(\"AUC:\", np.mean(auc_list_0th))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8061a-d90f-400c-a3d0-f4a011531fc7",
   "metadata": {},
   "source": [
    "### Bayesian online change point detection (BOCPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd04a9c-f4e4-4cb4-a67e-2710a1d3845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.1\n",
    "BETA = 1.0\n",
    "KAPPA = 1.0\n",
    "MU = 0.0\n",
    "DELAY = 15\n",
    "T = 200\n",
    "\n",
    "for LAMBDA in [100,600]:\n",
    "    for THRESHOLD in [0.1, 0.3]:\n",
    "        scores_bocpd = []\n",
    "        for i in range(N_trial):\n",
    "            X = data\n",
    "\n",
    "            # BOCPD\n",
    "            bocd = BOCD(partial(constant_hazard, LAMBDA),\n",
    "                        StudentT(ALPHA, BETA, KAPPA, MU), X)\n",
    "            change_points = []\n",
    "            scores = [np.nan] * DELAY\n",
    "            for x in X[:DELAY]:\n",
    "                bocd.update(x)\n",
    "            for x in X[DELAY:]:\n",
    "                bocd.update(x)\n",
    "                if bocd.growth_probs[DELAY] >= THRESHOLD:\n",
    "                    change_points.append(bocd.t - DELAY + 1)\n",
    "                score = np.sum(bocd.growth_probs[:bocd.t - DELAY] * 1.0 / (1.0 + np.arange(1, bocd.t - DELAY + 1)))\n",
    "                scores.append(score)\n",
    "\n",
    "            scores_bocpd.append(scores)\n",
    "\n",
    "        scores_bocpd = np.array(scores_bocpd)\n",
    "        auc_list = calc_auc_average(scores_bocpd,np.array([500,1000]),T=T)\n",
    "        print('LAMBDA =', LAMBDA, 'THRESHOLD =', THRESHOLD, 'AUC:', np.mean(auc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
